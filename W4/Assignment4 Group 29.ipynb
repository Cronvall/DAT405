{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-sTsDfIVKsmL"
   },
   "source": [
    "#DAT405 Introduction to Data Science and AI \n",
    "##2022-2023, Reading Period 1\n",
    "## Assignment 4: Spam classification using Naïve Bayes \n",
    "There will be an overall grade for this assignment. To get a pass grade (grade 5), you need to pass items 1-3 below. To receive higher grades, finish items 4 and 5 as well. \n",
    "\n",
    "The exercise takes place in a notebook environment where you can chose to use Jupyter or Google Colabs. We recommend you use Google Colabs as it will facilitate remote group-work and makes the assignment less technical. \n",
    "Hints:\n",
    "You can execute certain linux shell commands by prefixing the command with `!`. You can insert Markdown cells and code cells. The first you can use for documenting and explaining your results the second you can use writing code snippets that execute the tasks required.  \n",
    "\n",
    "In this assignment you will implement a Naïve Bayes classifier in Python that will classify emails into spam and non-spam (“ham”) classes.  Your program should be able to train on a given set of spam and “ham” datasets. \n",
    "You will work with the datasets available at https://spamassassin.apache.org/old/publiccorpus/. There are three types of files in this location: \n",
    "-\teasy-ham: non-spam messages typically quite easy to differentiate from spam messages. \n",
    "-\thard-ham: non-spam messages more difficult to differentiate \n",
    "-\tspam: spam messages \n",
    "\n",
    "**Execute the cell below to download and extract the data into the environment of the notebook -- it will take a few seconds.** If you chose to use Jupyter notebooks you will have to run the commands in the cell below on your local computer, with Windows you can use \n",
    "7zip (https://www.7-zip.org/download.html) to decompress the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wa37fBwRF-xe",
    "outputId": "0864185b-6475-4157-eb81-706f921b8703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-29 21:59:50--  https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1677144 (1.6M) [application/x-bzip2]\n",
      "Saving to: '20021010_easy_ham.tar.bz2.1'\n",
      "\n",
      "20021010_easy_ham.t 100%[===================>]   1.60M  10.4MB/s    in 0.2s    \n",
      "\n",
      "2022-11-29 21:59:50 (10.4 MB/s) - '20021010_easy_ham.tar.bz2.1' saved [1677144/1677144]\n",
      "\n",
      "--2022-11-29 21:59:50--  https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1021126 (997K) [application/x-bzip2]\n",
      "Saving to: '20021010_hard_ham.tar.bz2'\n",
      "\n",
      "20021010_hard_ham.t 100%[===================>] 997.19K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-11-29 21:59:50 (9.95 MB/s) - '20021010_hard_ham.tar.bz2' saved [1021126/1021126]\n",
      "\n",
      "--2022-11-29 21:59:51--  https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
      "Resolving spamassassin.apache.org (spamassassin.apache.org)... 151.101.2.132\n",
      "Connecting to spamassassin.apache.org (spamassassin.apache.org)|151.101.2.132|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1192582 (1.1M) [application/x-bzip2]\n",
      "Saving to: '20021010_spam.tar.bz2'\n",
      "\n",
      "20021010_spam.tar.b 100%[===================>]   1.14M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-11-29 21:59:51 (10.0 MB/s) - '20021010_spam.tar.bz2' saved [1192582/1192582]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Download and extract data\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_hard_ham.tar.bz2\n",
    "!wget https://spamassassin.apache.org/old/publiccorpus/20021010_spam.tar.bz2\n",
    "!tar -xjf 20021010_easy_ham.tar.bz2\n",
    "!tar -xjf 20021010_hard_ham.tar.bz2\n",
    "!tar -xjf 20021010_spam.tar.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdH1XTepLjZ3"
   },
   "source": [
    "*The* data is now in the three folders `easy_ham`, `hard_ham`, and `spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A53Gw00fBLG2",
    "outputId": "81eab863-9fd1-494b-e3e0-6a3dcaf32a5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 96768\n",
      "drwxr-xr-x     3 oscarcronvall  staff    96B  4 Feb  2022 \u001b[1m\u001b[36m$RECYCLE.BIN\u001b[m\u001b[m\n",
      "drwx------+   46 oscarcronvall  staff   1,4K 29 Nov 21:59 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x+   76 oscarcronvall  staff   2,4K 29 Nov 21:59 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff    14K 29 Nov 16:57 .DS_Store\n",
      "drwxr-xr-x     9 oscarcronvall  staff   288B 29 Sep  2021 \u001b[1m\u001b[36m.idea\u001b[m\u001b[m\n",
      "drwxr-xr-x     2 oscarcronvall  staff    64B 29 Nov 21:59 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\n",
      "-rw-r--r--     1 oscarcronvall  staff     0B 26 Aug  2021 .localized\n",
      "-rw-r--r--@    1 oscarcronvall  staff    45K 25 Maj  2022 1Password Emergency Kit A3-TRFSBQ-burtcorp.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   1,6M 23 Nov 12:50 20021010_easy_ham.tar.bz2\n",
      "-rw-r--r--     1 oscarcronvall  staff   1,6M 29 Jun  2004 20021010_easy_ham.tar.bz2.1\n",
      "-rw-r--r--     1 oscarcronvall  staff   997K 16 Dec  2004 20021010_hard_ham.tar.bz2\n",
      "-rw-r--r--     1 oscarcronvall  staff   1,1M 29 Jun  2004 20021010_spam.tar.bz2\n",
      "-rw-r--r--@    1 oscarcronvall  staff   1,5M 25 Nov 15:11 20030228_easy_ham.tar.bz2\n",
      "drwxrwxr-x@   10 oscarcronvall  staff   320B  1 Nov 15:59 \u001b[1m\u001b[36m2022-Java-main\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff   129K 21 Nov 11:27 22234009 Fakura armIT.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   132K 21 Nov 11:58 22234010 faktura armIT.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   128K 29 Nov 16:51 22234012 armit (1).pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   128K 29 Nov 16:50 22234012 armit.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   8,3K 22 Nov 22:27 Assignment4.ipynb\n",
      "-rw-r--r--@    1 oscarcronvall  staff    43K 29 Nov 21:58 Assignment4_min.ipynb\n",
      "-rw-r--r--@    1 oscarcronvall  staff    92K 29 Nov 11:16 CTK Quote IT- 20XX-XX-XXX (Small Project).pptx\n",
      "-rw-r--r--@    1 oscarcronvall  staff   319K 29 Nov 17:10 Faktura1217.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   133K 29 Nov 18:18 FakturaMall_NY.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff    26K 29 Nov 17:05 Faktura_210.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   1,8M 22 Nov 22:23 Group29-Assignment3.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   543K 10 Okt 09:54 Produktkatalog_ArmIT_21.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff    25M 11 Nov 23:57 Squad_replay_2022.11.09-20.46_Trim.mp4\n",
      "-rw-r--r--@    1 oscarcronvall  staff    57K  6 Nov 19:42 Standard Forkop.pdf\n",
      "drwxr-xr-x    14 oscarcronvall  staff   448B 17 Mar  2022 \u001b[1m\u001b[36mTMV206 -TENTOR\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff    66K 14 Nov 21:33 Transaktioner_2022-11-14_21-33-19.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff    73K 27 Nov 20:03 Transaktioner_2022-11-27_20-03-59.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff   1,8M 13 Okt 20:18 _R9A9395.jpg\n",
      "drwxr-xr-x     5 oscarcronvall  staff   160B 14 Nov 21:44 \u001b[1m\u001b[36mbokföring\u001b[m\u001b[m\n",
      "-rw-r--r--     1 oscarcronvall  staff   282B  4 Feb  2022 desktop.ini\n",
      "drwx--x--x@ 2553 oscarcronvall  staff    80K 29 Nov 21:59 \u001b[1m\u001b[36measy_ham\u001b[m\u001b[m\n",
      "drwx--x--x@ 2503 oscarcronvall  staff    78K 28 Feb  2003 \u001b[1m\u001b[36measy_ham 2\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff   9,8M 25 Nov 15:43 easy_ham.csv\n",
      "-rw-r--r--@    1 oscarcronvall  staff   206B 25 Maj  2022 github-recovery-codes.txt\n",
      "drwx--x--x   252 oscarcronvall  staff   7,9K 16 Dec  2004 \u001b[1m\u001b[36mhard_ham\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff    48K 25 Nov 17:31 invoice.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff    15K 18 Jun 23:03 namecheap-order-97706733.pdf\n",
      "-rw-------@    1 oscarcronvall  staff    26K 19 Nov 15:32 receipt.pdf\n",
      "-rw-r--r--@    1 oscarcronvall  staff    50K 31 Jul 12:36 resumé Oscar Cronvall.pdf\n",
      "drwxr-xr-x   503 oscarcronvall  staff    16K 10 Okt  2002 \u001b[1m\u001b[36mspam\u001b[m\u001b[m\n",
      "-rw-r--r--@    1 oscarcronvall  staff   178K 22 Okt 21:45 specifikation-for-edi-fakturaformat-svefaktura-1.0.xlsx\n",
      "drwxr-xr-x     8 oscarcronvall  staff   256B 17 Feb  2022 \u001b[1m\u001b[36mvideos\u001b[m\u001b[m\n",
      "\u001b[33m[W 2022-11-29 21:59:55.796 LabApp]\u001b[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
      "\u001b[33m[W 2022-11-29 21:59:55.796 LabApp]\u001b[m 'iopub_data_rate_limit' has moved from NotebookApp to ServerApp. This config will be passed to ServerApp. Be sure to update your config before our next release.\n",
      "\u001b[32m[I 2022-11-29 21:59:55.802 LabApp]\u001b[m JupyterLab extension loaded from /Users/oscarcronvall/opt/anaconda3/lib/python3.9/site-packages/jupyterlab\n",
      "\u001b[32m[I 2022-11-29 21:59:55.802 LabApp]\u001b[m JupyterLab application directory is /Users/oscarcronvall/opt/anaconda3/share/jupyter/lab\n",
      "\u001b[32m[I 21:59:55.806 NotebookApp]\u001b[m The port 8888 is already in use, trying another port.\n",
      "\u001b[32m[I 21:59:55.806 NotebookApp]\u001b[m The port 8889 is already in use, trying another port.\n",
      "\u001b[32m[I 21:59:55.807 NotebookApp]\u001b[m Serving notebooks from local directory: /Users/oscarcronvall/Downloads\n",
      "\u001b[32m[I 21:59:55.807 NotebookApp]\u001b[m Jupyter Notebook 6.4.12 is running at:\n",
      "\u001b[32m[I 21:59:55.807 NotebookApp]\u001b[m http://localhost:8890/?token=54663b43c2c4176c40c5e37a8d422c83c1d069f436642e70\n",
      "\u001b[32m[I 21:59:55.807 NotebookApp]\u001b[m  or http://127.0.0.1:8890/?token=54663b43c2c4176c40c5e37a8d422c83c1d069f436642e70\n",
      "\u001b[32m[I 21:59:55.807 NotebookApp]\u001b[m Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "\u001b[35m[C 21:59:55.810 NotebookApp]\u001b[m \n",
      "    \n",
      "    To access the notebook, open this file in a browser:\n",
      "        file:///Users/oscarcronvall/Library/Jupyter/runtime/nbserver-10647-open.html\n",
      "    Or copy and paste one of these URLs:\n",
      "        http://localhost:8890/?token=54663b43c2c4176c40c5e37a8d422c83c1d069f436642e70\n",
      "     or http://127.0.0.1:8890/?token=54663b43c2c4176c40c5e37a8d422c83c1d069f436642e70\n"
     ]
    }
   ],
   "source": [
    "!ls -lah\n",
    "!jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGlWPVnSNzT7"
   },
   "source": [
    "###1. Preprocessing: \n",
    "1.\tNote that the email files contain a lot of extra information, besides the actual message. Ignore that for now and run on the entire text. Further down (in the higher-grade part), you will be asked to filter out the headers and footers. \n",
    "2.\tWe don’t want to train and test on the same data. Split the spam and the ham datasets in a training set and a test set. (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZSTNZ_UMELo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Function that saves each mail from the folder in an array\n",
    "def save_data(dir):\n",
    "  _list = []\n",
    "\n",
    "  with os.scandir(dir) as files:\n",
    "    for file in files:\n",
    "      with open(file,\"r\",encoding = \"ISO-8859-1\") as file_open:\n",
    "        content = file_open.read()\n",
    "        _list.append(content)\n",
    "\n",
    "  return _list\n",
    "\n",
    "#Call the save_data function for the three folders\n",
    "easy_ham_mails = save_data('easy_ham')\n",
    "hard_ham_mails = save_data('hard_ham')\n",
    "spam_mails = save_data('spam')\n",
    "#Making labels for the threee different data sets \n",
    "#and for the ham combination data set\n",
    "spam_mails_label = ['spam']*len(spam_mails)\n",
    "hard_ham_mails_label = ['hardham']*(len(hard_ham_mails))\n",
    "easy_ham_mails_label = ['easyham']*len(easy_ham_mails)\n",
    "ham_mails_label = ['ham']*(len(easy_ham_mails + hard_ham_mails))\n",
    "\n",
    "#Using the train_test_split fuction from sklearn to \n",
    "#split the data into train and test. The train sample\n",
    "#is the 80% of the data and the test is the 20% of the data.\n",
    "#We have included the labels to have one for each train and \n",
    "#test with the same number of items as the train and test lists.\n",
    "\n",
    "spam_train, spam_test, spam_label_train, spam_label_test = train_test_split(spam_mails, spam_mails_label, test_size=0.2, random_state=42) #spam\n",
    "\n",
    "hard_ham_train, hard_ham_test, hard_ham_label_train, hard_ham_label_test = train_test_split(hard_ham_mails, hard_ham_mails_label, test_size=0.2, random_state=42) # hard ham\n",
    "\n",
    "easy_ham_train, easy_ham_test, easy_ham_label_train, easy_ham_label_test = train_test_split(easy_ham_mails, easy_ham_mails_label, test_size=0.2, random_state=42) # easy ham\n",
    "\n",
    "ham_train, ham_test, ham_label_train, ham_label_test = train_test_split(easy_ham_mails + hard_ham_mails, ham_mails_label, test_size=0.2, random_state=42) # combined ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI1bPDCvQxen"
   },
   "source": [
    "Your discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnbrbI0_OKCF"
   },
   "source": [
    "###2. Write a Python program that: \n",
    "1.\tUses four datasets (`hamtrain`, `spamtrain`, `hamtest`, and `spamtest`) \n",
    "2.\tTrains a Naïve Bayes classifier (e.g. Sklearn) on `hamtrain` and `spamtrain`, that classifies the test sets and reports True Positive and False Negative rates on the `hamtest` and `spamtest` datasets. You can use `CountVectorizer` to transform the email texts into vectors. Please note that there are different types of Naïve Bayes Classifier in SKlearn ([Documentation here](https://scikit-learn.org/stable/modules/naive_bayes.html)). Test two of these classifiers that are well suited for this problem\n",
    "- Multinomial Naive Bayes  \n",
    "- Bernoulli Naive Bayes. \n",
    "\n",
    "Please inspect the documentation to ensure input to the classifiers is appropriate. Discuss the differences between these two classifiers. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5-Ro9vV45N5"
   },
   "outputs": [],
   "source": [
    "#Necessary imports\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Naive_Bayes function that prints the True Positive and False Negative of \n",
    "#the previous train and test using the Multinomial and Bernuoulli Naive Bayes\n",
    "#and CountVectorizer from sklearn package.\n",
    "def Naive_Bayes(data_to_train_one, data_to_train_two, data_to_test_one, data_to_test_two, label_train_one, label_train_two, label_test_one, label_test_two):  \n",
    "    #Initialization of CountVectorizer, BernoulliNB and MultinomialNB\n",
    "    multi_NB = MultinomialNB()\n",
    "    bernoulli_NB = BernoulliNB()\n",
    "    count_vec = CountVectorizer()\n",
    "\n",
    "    #Transforming the train data set with CountVectorizer to vectors\n",
    "    #and fit the vectors with the Multinomial and Bernoulli Naive Bayes classifier\n",
    "    train = count_vec.fit_transform(data_to_train_one + data_to_train_two)\n",
    "    multi_NB.fit(train, label_train_one + label_train_two)\n",
    "    bernoulli_NB.fit(train, label_train_one + label_train_two)\n",
    "\n",
    "    #Now is transformed the two test data sets with CountVectorizer \n",
    "    #and perform the classification with the predict with  \n",
    "    #Multinomial and Bernoulli Naive Bayes    \n",
    "    test_one = count_vec.transform(data_to_test_one)\n",
    "    multi_NB_test_one = multi_NB.predict(test_one)\n",
    "    bernoulli_NB_test_one = bernoulli_NB.predict(test_one)\n",
    "\n",
    "    test_two = count_vec.transform(data_to_test_two)\n",
    "    multi_NB_test_two = multi_NB.predict(test_two)\n",
    "    bernoulli_NB_test_two = bernoulli_NB.predict(test_two)\n",
    "    \n",
    "    #Calculated the accuracy on the given test_set of the\n",
    "    #Multinomial and Bernoulli Naive Bayes\n",
    "    test_set = count_vec.transform(data_to_test_one + data_to_test_two)\n",
    "    multi_NB_accuracy = multi_NB .score(test_set, label_test_one + label_test_two)\n",
    "    bernoulli_NB_accuracy = bernoulli_NB .score(test_set, label_test_one + label_test_two)\n",
    "\n",
    "    #Printing Multinomial results\n",
    "    unique, counts = np.unique(multi_NB_test_one, return_counts=True)\n",
    "    print(f\"Multinomial True Positives: {dict(zip(unique, counts))[label_test_one[0]]}\")\n",
    "    unique, counts = np.unique(multi_NB_test_two, return_counts=True)\n",
    "    print(f\"Multinomial False Negatives: {dict(zip(unique, counts))[label_test_two[0]]}\")\n",
    "    print(f\"Multinomial Accuracy: {multi_NB_accuracy:,.2f}\\n\")\n",
    "    \n",
    "    #Printing Bernoulli results\n",
    "    unique, counts = np.unique(bernoulli_NB_test_one, return_counts=True)\n",
    "    print(f\"Bernoulli True Positives: {dict(zip(unique, counts))[label_test_one[0]]}\")    \n",
    "    unique, counts = np.unique(bernoulli_NB_test_two, return_counts=True)\n",
    "    print(f\"Bernoulli False Negatives: {dict(zip(unique, counts))[label_test_two[0]]}\")\n",
    "    print(f\"Bernoulli Accuracy: {bernoulli_NB_accuracy:,.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWtpjMhX5GjK",
    "outputId": "e8b2b470-2b63-452c-df53-f11f98297363"
   },
   "outputs": [],
   "source": [
    "Naive_Bayes(ham_train, spam_train, ham_test, spam_test, ham_label_train, spam_label_train, ham_label_test, spam_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEXZgab6QEB6"
   },
   "source": [
    "Discussion:\n",
    "\n",
    "For this part we have used the Multinomial and Bernoulli Niave Bayes from SKlearn (also the CountVectorizer), all the information that we have used to know how to work with this three functions is from the official web page and some examples from internet users. We know that Bernoulli Naive Bayes is better compare with Multinomial Naive Bayes when we have to hand boolean or binary values, in the case of Multinomial is used when we have to hand with discrete values.\n",
    "\n",
    "From the first moment that we knew the type of data and we take a look we thought that the Multinomial classifier will fit in a better way and, finally, with the results and the accuracy our suspicions were true. We thought that because of the limitation from Bernoulli of boolean or binary values because in many spam emails as they are publicity or spams some elements can be repitied, elements like symbols, and in the case of Bernoulli can not interpret this type of symbols in the same way as Multinomial classifier does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDFS3uFFUcS7"
   },
   "source": [
    "### 3.Run your program on \n",
    "-\tSpam versus easy-ham \n",
    "-\tSpam versus hard-ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gool_zb8Qzzy",
    "outputId": "5db0d48e-8695-4715-d6a4-4206a90ae2a8"
   },
   "outputs": [],
   "source": [
    "#Spam vs Easy-ham\n",
    "print(\"Spam vs Easy-ham \\n--------------------------------\")\n",
    "Naive_Bayes(easy_ham_train, spam_train, easy_ham_test, spam_test, easy_ham_label_train, spam_label_train, easy_ham_label_test, spam_label_test)\n",
    "#Spam vs Hard-ham\n",
    "print(\"Spam vs Hard-ham \\n--------------------------------\")\n",
    "Naive_Bayes(hard_ham_train, spam_train, hard_ham_test, spam_test, hard_ham_label_train, spam_label_train, hard_ham_label_test, spam_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkfQWBB4UhYd"
   },
   "source": [
    "###4.\tTo avoid classification based on common and uninformative words it is common to filter these out. \n",
    "\n",
    "**a.** Argue why this may be useful. Try finding the words that are too common/uncommon in the dataset. \n",
    "\n",
    "**b.** Use the parameters in Sklearn’s `CountVectorizer` to filter out these words. Update the program from point 3 and run it on your data and report your results.\n",
    "\n",
    "You have two options to do this in Sklearn: either using the words found in part (a) or letting Sklearn do it for you. Argue for your decision-making.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qt7ELzEqUfas"
   },
   "outputs": [],
   "source": [
    "# We have decided to use the stop words provided by sklearn.\n",
    "# Why we did this is because they have about 300 words here that all are determined to be 'uninformative'\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from collections import Counter\n",
    "\n",
    "coding_chars = ['<','>','=','+','@','{','}','[',']','px'] # used to exclude \"words\" that would occur in html code and email adresses\n",
    "\n",
    "def words_exclude_stopwords(mails):\n",
    "  for mail in mails:\n",
    "    terms = mail.split()\n",
    "    for word in list(terms):  # using a copy since iteration and modification at same time doesn't work\n",
    "      if word in ENGLISH_STOP_WORDS: #or any(char in word for char in coding_chars)\n",
    "        terms.remove(word)\n",
    "  return terms\n",
    "\n",
    "# Used to find the most common words in each data set (easy ham , hard ham, spam)\n",
    "def get_k_common_words(texts, k):\n",
    "  total_txt = \"\"\n",
    "  for text in texts:\n",
    "    total_txt = total_txt + \" \" +text\n",
    "  split_text = total_txt.split()\n",
    "  counter = Counter(split_text)\n",
    "  result = counter.most_common(k)\n",
    "  print(\"Average word occurance:\",average_occurance(counter))\n",
    "  return result\n",
    "\n",
    "def get_k_common_words_no_code(texts, k):\n",
    "  total_txt = \"\"\n",
    "  for text in texts:\n",
    "    if not any(char in text for char in coding_chars):\n",
    "      total_txt = total_txt + \" \" +text\n",
    "  split_text = total_txt.split()\n",
    "  counter = Counter(split_text)\n",
    "  result = counter.most_common(k)\n",
    "  print(\"Average word occurance:\",average_occurance(counter))\n",
    "  return result\n",
    "\n",
    "def average_occurance(map):\n",
    "  total = 0\n",
    "  itterations = 0\n",
    "  for key in map.keys():\n",
    "    itterations = itterations +1\n",
    "    total = total + map[key]\n",
    "  return (total / itterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PniS7qwS7OkN"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "#Naive_Bayes function that prints the True Positive and False Negative of \n",
    "#the previous train and test using the Multinomial and Bernuoulli Naive Bayes\n",
    "#and CountVectorizer from sklearn package.\n",
    "def Naive_Bayes_exclude(data_to_train_one, data_to_train_two, data_to_test_one, data_to_test_two, label_train_one, label_train_two, label_test_one, label_test_two):  \n",
    "    #Initialization of CountVectorizer, BernoulliNB and MultinomialNB\n",
    "    multi_NB = MultinomialNB()\n",
    "    bernoulli_NB = BernoulliNB()\n",
    "    count_vec = CountVectorizer(vocabulary=ENGLISH_STOP_WORDS) # Excluding all words/terms that are in ENGLISH_STOP_WORDS\n",
    "\n",
    "    #Transforming the train data set with CountVectorizer to vectors\n",
    "    #and fit the vectors with the Multinomial and Bernoulli Naive Bayes classifier\n",
    "    train = count_vec.fit_transform(data_to_train_one + data_to_train_two)\n",
    "    multi_NB.fit(train, label_train_one + label_train_two)\n",
    "    bernoulli_NB.fit(train, label_train_one + label_train_two)\n",
    "\n",
    "    #Now is transformed the two test data sets with CountVectorizer \n",
    "    #and perform the classification with the predict with  \n",
    "    #Multinomial and Bernoulli Naive Bayes    \n",
    "    test_one = count_vec.transform(data_to_test_one)\n",
    "    multi_NB_test_one = multi_NB.predict(test_one)\n",
    "    bernoulli_NB_test_one = bernoulli_NB.predict(test_one)\n",
    "\n",
    "    test_two = count_vec.transform(data_to_test_two)\n",
    "    multi_NB_test_two = multi_NB.predict(test_two)\n",
    "    bernoulli_NB_test_two = bernoulli_NB.predict(test_two)\n",
    "    \n",
    "    #Calculated the accuracy on the given test_set of the\n",
    "    #Multinomial and Bernoulli Naive Bayes\n",
    "    test_set = count_vec.transform(data_to_test_one + data_to_test_two)\n",
    "    multi_NB_accuracy = multi_NB .score(test_set, label_test_one + label_test_two)\n",
    "    bernoulli_NB_accuracy = bernoulli_NB .score(test_set, label_test_one + label_test_two)\n",
    "\n",
    "    #Printing Multinomial results\n",
    "    unique, counts = np.unique(multi_NB_test_one, return_counts=True)\n",
    "    print(f\"Multinomial True Positives: {dict(zip(unique, counts))[label_test_one[0]]}\")\n",
    "    unique, counts = np.unique(multi_NB_test_two, return_counts=True)\n",
    "    print(f\"Multinomial False Negatives: {dict(zip(unique, counts))[label_test_two[0]]}\")\n",
    "    print(f\"Multinomial Accuracy: {multi_NB_accuracy:,.2f}\\n\")\n",
    "    \n",
    "    #Printing Bernoulli results\n",
    "    unique, counts = np.unique(bernoulli_NB_test_one, return_counts=True)\n",
    "    print(f\"Bernoulli True Positives: {dict(zip(unique, counts))[label_test_one[0]]}\")    \n",
    "    unique, counts = np.unique(bernoulli_NB_test_two, return_counts=True)\n",
    "    print(f\"Bernoulli False Negatives: {dict(zip(unique, counts))[label_test_two[0]]}\")\n",
    "    print(f\"Bernoulli Accuracy: {bernoulli_NB_accuracy:,.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2_2FQ7sdCaN"
   },
   "outputs": [],
   "source": [
    "# reinstantiate the training, test & label's variables\n",
    "spam_train, spam_test, spam_label_train, spam_label_test = train_test_split(spam_mails, spam_mails_label, test_size=0.2, random_state=42) #spam\n",
    "\n",
    "hard_ham_train, hard_ham_test, hard_ham_label_train, hard_ham_label_test = train_test_split(hard_ham_mails, hard_ham_mails_label, test_size=0.2, random_state=42) # hard ham\n",
    "\n",
    "easy_ham_train, easy_ham_test, easy_ham_label_train, easy_ham_label_test = train_test_split(easy_ham_mails, easy_ham_mails_label, test_size=0.2, random_state=42) # easy ham\n",
    "\n",
    "ham_train, ham_test, ham_label_train, ham_label_test = train_test_split(easy_ham_mails + hard_ham_mails, ham_mails_label, test_size=0.2, random_state=42) # combined ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwxG1fNA74mJ",
    "outputId": "8c4d56dc-f08b-4bf1-fcb7-6bccdba709ef"
   },
   "outputs": [],
   "source": [
    "#Spam vs Easy-ham\n",
    "print(\"-------------\")\n",
    "print('easy ham')\n",
    "print(\"-------------\")\n",
    "Naive_Bayes_exclude(easy_ham_train, spam_train, easy_ham_test, spam_test, easy_ham_label_train, spam_label_train, easy_ham_label_test, spam_label_test)\n",
    "print(\"-------------\")\n",
    "print('hard ham')\n",
    "print(\"-------------\")\n",
    "#Spam vs Hard-ham\n",
    "Naive_Bayes_exclude(hard_ham_train, spam_train, hard_ham_test, spam_test, hard_ham_label_train, spam_label_train, hard_ham_label_test, spam_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmap5cz2Ponp"
   },
   "source": [
    "### **Below we are printing the 10 most common \"words\" in each data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxT0I0T3than"
   },
   "source": [
    "Why we want to look at both what \"words\" are most frequent is so that we can get an understanding of what type of language and or coding tags that are used accross all the emails. For example we can very easy see that a lot of the emails in the hard ham data set has a variety of HTML tags.\n",
    "We also want to know the average word occurance so that we can get a grasp of the deviation between the most frequent \"words\" and the rest is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ao2QcsQYO9zY",
    "outputId": "a8883002-174e-483c-bd25-19561e5fc2e2"
   },
   "outputs": [],
   "source": [
    "easy_ham_words = words_exclude_stopwords(easy_ham_mails)\n",
    "print(\"Top 10 most frequent words in the easy ham data set: \",get_k_common_words(easy_ham_words, 10), \"\\n ----\")\n",
    "hard_ham_words = words_exclude_stopwords(hard_ham_mails)\n",
    "print(\"Top 10 most frequent words in the hard ham data set: \",get_k_common_words(hard_ham_words, 10), \"\\n ----\")\n",
    "spam_words = words_exclude_stopwords(spam_mails)\n",
    "print(\"Top 10 most frequent words in the spam data set: \",get_k_common_words(spam_words, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fg5fghSSvNc4"
   },
   "source": [
    "If we now instead try to remove all the HTML tags and other common characters in code such as brackets we get the following result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrYUuRY-vblw",
    "outputId": "ec82ae27-6aa0-47a3-ad31-64b81a00f12a"
   },
   "outputs": [],
   "source": [
    "easy_ham_words = words_exclude_stopwords(easy_ham_mails)\n",
    "print(\"Top 10 most frequent words in the easy ham data set: \",get_k_common_words_no_code(easy_ham_words, 10), \"\\n ----\")\n",
    "hard_ham_words = words_exclude_stopwords(hard_ham_mails)\n",
    "print(\"Top 10 most frequent words in the hard ham data set: \",get_k_common_words_no_code(hard_ham_words, 10), \"\\n ----\")\n",
    "spam_words = words_exclude_stopwords(spam_mails)\n",
    "print(\"Top 10 most frequent words in the spam data set: \",get_k_common_words_no_code(spam_words, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gLRSI2dV5aYN"
   },
   "source": [
    "Something worth noting when reading the average word occurance for both hard ham emails and spam is that they are very simular in comparison to the easy ham data set. Altough this doesn't prove anything more than that the hard ham data sets share some aspects with the spam data set.\n",
    "\n",
    "Another interesting thing is that the average occurance of words in the spam data set increased. So this means that the content of these emails are filled with words that doesn't provide value to the message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcyVfOZFU4F_"
   },
   "source": [
    "###5. Eeking out further performance\n",
    "Filter out the headers and footers of the emails before you run on them. The format may vary somewhat between emails, which can make this a bit tricky, so perfect filtering is not required. Run your program again and answer the following questions: \n",
    "-\tDoes the result improve from 3 and 4? \n",
    "- The split of the data set into a training set and a test set can lead to very skewed results. Why is this, and do you have suggestions on remedies? \n",
    "- What do you expect would happen if your training set were mostly spam messages while your test set were mostly ham messages? \n",
    "\n",
    "Re-estimate your classifier using `fit_prior` parameter set to `false`, and answer the following questions:\n",
    "- What does this parameter mean?\n",
    "- How does this alter the predictions? Discuss why or why not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVqK1GRkCDB7"
   },
   "outputs": [],
   "source": [
    "# Reasoning behind this function is that since some emails contain the footer marking in the form of HTML comments: <!-- footer --> <!-- /footer -->\n",
    "# We are searching for the first footer tag and when that one is found we stop reading the words into the resulting filitered string\n",
    "# But when the second footer tag is found we will start appending words to the resulting string again\n",
    "\n",
    "def remove_footer(mail_list):\n",
    "  result_list = []\n",
    "  discovered_footer = False\n",
    "  for mail in mail_list:\n",
    "    resulting_mail = \"\"\n",
    "    rows = mail.split()\n",
    "    for word in rows:\n",
    "      if \"footer\" in word:\n",
    "        discovered_footer = not discovered_footer\n",
    "      if not discovered_footer:\n",
    "        resulting_mail = resulting_mail + str(word)\n",
    "    result_list.append(resulting_mail)\n",
    "  return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_nyGug9U4f3"
   },
   "outputs": [],
   "source": [
    "# Remove all terms that include the word subject, this since the email format uses subject as a tag for it's header\n",
    "def remove_header(mail_list):\n",
    "  result_list = []\n",
    "  for mail in mail_list:\n",
    "    resulting_mail = \"\"\n",
    "    rows = mail.split()\n",
    "    for word in rows:\n",
    "      if not \"subject\" in str(word):\n",
    "        resulting_mail = resulting_mail + str(word)\n",
    "    result_list.append(resulting_mail)\n",
    "  return result_list\n",
    "\n",
    "# Nesting our two functions remove_footer() & remove_header to remove both footers and headers\n",
    "\n",
    "easy_ham_filtered = remove_footer(remove_header(easy_ham_mails))\n",
    "hard_ham_filtered = remove_footer(remove_header(hard_ham_mails))\n",
    "spam_filtered = remove_footer(remove_header(spam_mails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND6FKoexVAhW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-J4Sskm-G9E",
    "outputId": "66f456c4-8515-4f14-8f27-28d1bacb3fed"
   },
   "outputs": [],
   "source": [
    "#Assuring ourselfs that both footer and subject tags are gone\n",
    "print(\"subject\" in easy_ham_filtered)\n",
    "print(\"subject\" in hard_ham_filtered)\n",
    "print(\"subject\" in spam_filtered)\n",
    "print(\"footer\" in easy_ham_filtered)\n",
    "print(\"footer\" in hard_ham_filtered)\n",
    "print(\"footer\" in spam_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aF4B63X0FQvV"
   },
   "outputs": [],
   "source": [
    "#Making new labels after the filtered \n",
    "spam_mails_label = ['spam']*len(spam_filtered)\n",
    "hard_ham_mails_label = ['hardham']*(len(hard_ham_filtered))\n",
    "easy_ham_mails_label = ['easyham']*len(easy_ham_filtered)\n",
    "ham_mails_label = ['ham']*(len(hard_ham_filtered + easy_ham_filtered))\n",
    "\n",
    "# reinstantiate the training, test & label's variables\n",
    "spam_train, spam_test, spam_label_train, spam_label_test = train_test_split(spam_mails, spam_mails_label, test_size=0.2, random_state=42) #spam\n",
    "\n",
    "hard_ham_train, hard_ham_test, hard_ham_label_train, hard_ham_label_test = train_test_split(hard_ham_filtered, hard_ham_mails_label, test_size=0.2, random_state=42) # hard ham\n",
    "\n",
    "easy_ham_train, easy_ham_test, easy_ham_label_train, easy_ham_label_test = train_test_split(easy_ham_filtered, easy_ham_mails_label, test_size=0.2, random_state=42) # easy ham\n",
    "\n",
    "ham_train, ham_test, ham_label_train, ham_label_test = train_test_split(easy_ham_mails + hard_ham_mails, ham_mails_label, test_size=0.2, random_state=42) # combined ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1FhK5BuRI1_b",
    "outputId": "37f86d33-d2e5-4992-990c-55da630d759c"
   },
   "outputs": [],
   "source": [
    "#Spam vs Easy-ham\n",
    "print(\"-------------\")\n",
    "print('easy ham')\n",
    "print(\"-------------\")\n",
    "Naive_Bayes_exclude(easy_ham_train, spam_train, easy_ham_test, spam_test, easy_ham_label_train, spam_label_train, easy_ham_label_test, spam_label_test)\n",
    "print(\"-------------\")\n",
    "print('hard ham')\n",
    "print(\"-------------\")\n",
    "#Spam vs Hard-ham\n",
    "Naive_Bayes_exclude(hard_ham_train, spam_train, hard_ham_test, spam_test, hard_ham_label_train, spam_label_train, hard_ham_label_test, spam_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wDFS3uFFUcS7"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
